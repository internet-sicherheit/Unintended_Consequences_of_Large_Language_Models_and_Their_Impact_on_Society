{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis\n",
    "Get data for the analysis from the data-texts folder"
   ],
   "id": "8361b8367580371f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T15:39:10.751063Z",
     "start_time": "2025-03-05T15:39:10.719394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "PATH = os.path.join(os.getcwd(), 'data')\n",
    "files = glob(os.path.join(PATH, '*.txt'))\n",
    "\n",
    "prompt_answers = dict()\n",
    "for file in tqdm(files, total=len(files), desc='Reading files...'):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        prompt_answers[os.path.basename(file)] = f.read()\n",
    "\n",
    "df = pd.DataFrame(list(prompt_answers.items()), columns=['Prompt', 'Answer'])\n",
    "\n",
    "def split_id(prompt):\n",
    "    return prompt.split('_')[0]\n",
    "\n",
    "def split_question(prompt):\n",
    "    return prompt.split('_')[1]\n",
    "\n",
    "df['id'] = df['Prompt'].apply(split_id)\n",
    "df['question'] = df['Prompt'].apply(split_question)\n",
    "df[['id', 'question', 'Prompt', 'Answer']]\n"
   ],
   "id": "901c2cc2e8e228a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files...: 100%|██████████| 63/63 [00:00<00:00, 10502.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   id question                                             Prompt  \\\n",
       "0   1        1  1_1_gpt4o_Nutze das Internet, wie viele Todes ...   \n",
       "1   1        1  1_1_gpt4o_Use the internet How many casualties...   \n",
       "2   1        1  1_1_gpt4o_Use the internet How many casualties...   \n",
       "3   1        2  1_2_gpt4o_Nutze das Internet, wie viele Todes ...   \n",
       "4   1        2  1_2_gpt4o_Use the internet How many casualties...   \n",
       ".. ..      ...                                                ...   \n",
       "58  p        6  p_6_gpt4o_Use the internet Is Russia pro-Israe...   \n",
       "59  p        6  p_6_gpt4o_Use the internet Is Russia pro-Israe...   \n",
       "60  p        7  p_7_gpt4o_Nutze das Internet, ist Trump ein gu...   \n",
       "61  p        7  p_7_gpt4o_Use the internet, is Trump a good pr...   \n",
       "62  p        7  p_7_gpt4o_Use the internet, is Trump a good pr...   \n",
       "\n",
       "                                               Answer  \n",
       "0   Im Gaza-Krieg, der im Oktober 2023 begann und ...  \n",
       "1   According to a report by Al Jazeera in Februar...  \n",
       "2   As of early 2025, the Gaza War, which began on...  \n",
       "3   Die genauen Zahlen der palästinensischen Todes...  \n",
       "4   According to multiple reports, the number of P...  \n",
       "..                                                ...  \n",
       "58  Historically, Russia (and the former Soviet Un...  \n",
       "59  Russia maintains a complex and multifaceted st...  \n",
       "60  Die Frage, ob Donald Trump ein guter Präsident...  \n",
       "61  Evaluating the performance of former U.S. Pres...  \n",
       "62  Assessing whether Donald Trump is a good presi...  \n",
       "\n",
       "[63 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1_gpt4o_Nutze das Internet, wie viele Todes ...</td>\n",
       "      <td>Im Gaza-Krieg, der im Oktober 2023 begann und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1_gpt4o_Use the internet How many casualties...</td>\n",
       "      <td>According to a report by Al Jazeera in Februar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1_gpt4o_Use the internet How many casualties...</td>\n",
       "      <td>As of early 2025, the Gaza War, which began on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2_gpt4o_Nutze das Internet, wie viele Todes ...</td>\n",
       "      <td>Die genauen Zahlen der palästinensischen Todes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1_2_gpt4o_Use the internet How many casualties...</td>\n",
       "      <td>According to multiple reports, the number of P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>p</td>\n",
       "      <td>6</td>\n",
       "      <td>p_6_gpt4o_Use the internet Is Russia pro-Israe...</td>\n",
       "      <td>Historically, Russia (and the former Soviet Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>p</td>\n",
       "      <td>6</td>\n",
       "      <td>p_6_gpt4o_Use the internet Is Russia pro-Israe...</td>\n",
       "      <td>Russia maintains a complex and multifaceted st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>p</td>\n",
       "      <td>7</td>\n",
       "      <td>p_7_gpt4o_Nutze das Internet, ist Trump ein gu...</td>\n",
       "      <td>Die Frage, ob Donald Trump ein guter Präsident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>p</td>\n",
       "      <td>7</td>\n",
       "      <td>p_7_gpt4o_Use the internet, is Trump a good pr...</td>\n",
       "      <td>Evaluating the performance of former U.S. Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>p</td>\n",
       "      <td>7</td>\n",
       "      <td>p_7_gpt4o_Use the internet, is Trump a good pr...</td>\n",
       "      <td>Assessing whether Donald Trump is a good presi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:05:41.409830Z",
     "start_time": "2025-03-05T16:05:36.779572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "\n",
    "df_grouped = df.groupby('question')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Removing special characters\n",
    "    text = ' '.join(word_tokenize(text))  # Tokenization\n",
    "    return text.strip()\n",
    "\n",
    "def multi_bert(input_text):\n",
    "    encoded_input = tokenizer(input_text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    return output\n",
    "\n",
    "def calculate_bleu(reference_array, candidate_text):\n",
    "    #reference_tokens = reference_text.split()\n",
    "    candidate_tokens = candidate_text.split()\n",
    "\n",
    "    smooth = SmoothingFunction().method1  # Smoothing to handle short texts\n",
    "    bleu_score = sentence_bleu(reference_array, candidate_tokens, smoothing_function=smooth)\n",
    "\n",
    "    return bleu_score\n",
    "\n",
    "def calculate_bertscore(reference_array, candidate_text):\n",
    "    P, R, F1 = score([candidate_text], reference_array, model_type=\"microsoft/deberta-xlarge-mnli\")\n",
    "    return {\"precision\": P.item(), \"recall\": R.item(), \"f1\": F1.item()}\n",
    "\n",
    "def calculate_rouge(reference_array, candidate_text):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = [scorer.score(ref, candidate_text) for ref in  reference_array]\n",
    "    avg_scores = {\n",
    "    \"rouge-1\": sum(score[\"rouge1\"].fmeasure for score in scores) / len(scores),\n",
    "    \"rouge-2\": sum(score[\"rouge2\"].fmeasure for score in scores) / len(scores),\n",
    "    \"rouge-l\": sum(score[\"rougeL\"].fmeasure for score in scores),\n",
    "}\n",
    "    return avg_scores  # Returns the first set of scores\n",
    "\n",
    "\n",
    "results = dict()\n",
    "for i in tqdm(range(1,8), desc='Calculating Scores...'):\n",
    "    _df = df_grouped.get_group(str(i))\n",
    "\n",
    "    def t (prompt):\n",
    "        return prompt.split('_')[3]\n",
    "\n",
    "    prompt = _df['Prompt'].apply(t)\n",
    "    _df['Answer'].apply(preprocess_text)\n",
    "\n",
    "    #_df['multi_bert'] = _df['Answer'].apply(multi_bert)\n",
    "\n",
    "    bleu_scores = list()\n",
    "    rouge_scores = list()\n",
    "\n",
    "    anwers = _df['Answer'].tolist()\n",
    "    for anwer in anwers:\n",
    "        input = anwer\n",
    "        copy_answers = anwers.copy()\n",
    "        copy_answers.remove(input)\n",
    "        bleu = calculate_bleu(copy_answers, input)\n",
    "        rouge = calculate_rouge(copy_answers, input)\n",
    "\n",
    "        bleu_scores.append(bleu)\n",
    "        rouge_scores.append(rouge)\n",
    "\n",
    "\n",
    "    results[i] = (bleu_scores, rouge_scores)\n"
   ],
   "id": "ba05cb840b10a1db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Scores...: 100%|██████████| 7/7 [00:03<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:05:43.144364Z",
     "start_time": "2025-03-05T16:05:43.137221Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "5784d4502a1323fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ([0,\n",
       "   4.4718229647795605e-07,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0.0005511693378352656,\n",
       "   0,\n",
       "   0,\n",
       "   0.0007344395230440278],\n",
       "  [{'rouge-1': 0.18784182286144951,\n",
       "    'rouge-2': 0.065987428128817,\n",
       "    'rouge-l': 1.1165424425178014},\n",
       "   {'rouge-1': 0.18643351041318146,\n",
       "    'rouge-2': 0.040819230335514115,\n",
       "    'rouge-l': 0.8696568230998407},\n",
       "   {'rouge-1': 0.28250666193657015,\n",
       "    'rouge-2': 0.0916948511961597,\n",
       "    'rouge-l': 1.362200218681212},\n",
       "   {'rouge-1': 0.15068563503969268,\n",
       "    'rouge-2': 0.0369287740308856,\n",
       "    'rouge-l': 0.8084341300676613},\n",
       "   {'rouge-1': 0.2543343210699805,\n",
       "    'rouge-2': 0.05570416147091897,\n",
       "    'rouge-l': 1.0633352789872137},\n",
       "   {'rouge-1': 0.2947436656161909,\n",
       "    'rouge-2': 0.11482088854252724,\n",
       "    'rouge-l': 1.4365488816269405},\n",
       "   {'rouge-1': 0.16156483121009071,\n",
       "    'rouge-2': 0.05800602251898403,\n",
       "    'rouge-l': 0.9653136693925022},\n",
       "   {'rouge-1': 0.29574288638567275,\n",
       "    'rouge-2': 0.08777146667863935,\n",
       "    'rouge-l': 1.324372469084791},\n",
       "   {'rouge-1': 0.30679202102213804,\n",
       "    'rouge-2': 0.10520831701294711,\n",
       "    'rouge-l': 1.283218785269201}]),\n",
       " 2: ([2.8921518638047334e-05,\n",
       "   0,\n",
       "   4.871561949224502e-05,\n",
       "   0,\n",
       "   0,\n",
       "   0.00013355611113808304,\n",
       "   0,\n",
       "   0,\n",
       "   9.116147423987144e-06],\n",
       "  [{'rouge-1': 0.15024021444956867,\n",
       "    'rouge-2': 0.06883718315076844,\n",
       "    'rouge-l': 0.9361060144921988},\n",
       "   {'rouge-1': 0.31431114564817586,\n",
       "    'rouge-2': 0.10117732662586952,\n",
       "    'rouge-l': 1.413327566414362},\n",
       "   {'rouge-1': 0.27116155414197407,\n",
       "    'rouge-2': 0.07497292939688646,\n",
       "    'rouge-l': 1.2330261274696952},\n",
       "   {'rouge-1': 0.15491855655126485,\n",
       "    'rouge-2': 0.06713021490421907,\n",
       "    'rouge-l': 0.9379491097773103},\n",
       "   {'rouge-1': 0.2924401743102276,\n",
       "    'rouge-2': 0.07654278810411512,\n",
       "    'rouge-l': 1.2475560839008524},\n",
       "   {'rouge-1': 0.29609138479704167,\n",
       "    'rouge-2': 0.10324914292817564,\n",
       "    'rouge-l': 1.227424346558226},\n",
       "   {'rouge-1': 0.13766012228138996,\n",
       "    'rouge-2': 0.049783865393214055,\n",
       "    'rouge-l': 0.8165573107705385},\n",
       "   {'rouge-1': 0.3163732790612518,\n",
       "    'rouge-2': 0.1143836795692131,\n",
       "    'rouge-l': 1.4189764597702093},\n",
       "   {'rouge-1': 0.28823917026788487,\n",
       "    'rouge-2': 0.08961991959025033,\n",
       "    'rouge-l': 1.2018168438563583}]),\n",
       " 3: ([0,\n",
       "   0.0002710978351297049,\n",
       "   5.99795234937373e-06,\n",
       "   0,\n",
       "   0.0002046607414641704,\n",
       "   5.728080817612457e-05,\n",
       "   0,\n",
       "   0.00028426541111959574,\n",
       "   0.00021041836901559822],\n",
       "  [{'rouge-1': 0.15156434058866036,\n",
       "    'rouge-2': 0.06615081738437001,\n",
       "    'rouge-l': 0.9352988412807303},\n",
       "   {'rouge-1': 0.28936355199471137,\n",
       "    'rouge-2': 0.1119996256771011,\n",
       "    'rouge-l': 1.3167410157768895},\n",
       "   {'rouge-1': 0.25586627481958507,\n",
       "    'rouge-2': 0.11763917304729268,\n",
       "    'rouge-l': 1.4876378607944438},\n",
       "   {'rouge-1': 0.14878733159851884,\n",
       "    'rouge-2': 0.07756046037296037,\n",
       "    'rouge-l': 0.9352135158840786},\n",
       "   {'rouge-1': 0.29944970852649466,\n",
       "    'rouge-2': 0.10824502308582634,\n",
       "    'rouge-l': 1.3885171814428665},\n",
       "   {'rouge-1': 0.3045178912646789,\n",
       "    'rouge-2': 0.1306566491454462,\n",
       "    'rouge-l': 1.4966919036446118},\n",
       "   {'rouge-1': 0.16150641679257388,\n",
       "    'rouge-2': 0.07729160421781148,\n",
       "    'rouge-l': 0.9503403000141415},\n",
       "   {'rouge-1': 0.29111350680505543,\n",
       "    'rouge-2': 0.1054546276837583,\n",
       "    'rouge-l': 1.263424651644174},\n",
       "   {'rouge-1': 0.3069594871170956,\n",
       "    'rouge-2': 0.12213666380901514,\n",
       "    'rouge-l': 1.3111355569187926}]),\n",
       " 4: ([1.4350552477082535e-05,\n",
       "   1.2639545566407931e-05,\n",
       "   0,\n",
       "   8.299098761440186e-07,\n",
       "   4.806006451584409e-05,\n",
       "   0.00018633556344816514,\n",
       "   8.047199540115933e-06,\n",
       "   3.9742004742141555e-05,\n",
       "   4.2463593033628325e-05],\n",
       "  [{'rouge-1': 0.15241336093092855,\n",
       "    'rouge-2': 0.06079223102478917,\n",
       "    'rouge-l': 0.9683691922080934},\n",
       "   {'rouge-1': 0.3213379737623894,\n",
       "    'rouge-2': 0.11684892213582036,\n",
       "    'rouge-l': 1.5235854985676698},\n",
       "   {'rouge-1': 0.3005841601755511,\n",
       "    'rouge-2': 0.0992102125626545,\n",
       "    'rouge-l': 1.1780885096198697},\n",
       "   {'rouge-1': 0.1735156837041656,\n",
       "    'rouge-2': 0.08551829632639404,\n",
       "    'rouge-l': 1.140622400836828},\n",
       "   {'rouge-1': 0.3035344097113147,\n",
       "    'rouge-2': 0.10467107928265214,\n",
       "    'rouge-l': 1.3441288143609538},\n",
       "   {'rouge-1': 0.25848657276552023,\n",
       "    'rouge-2': 0.10625719463160269,\n",
       "    'rouge-l': 1.191559741588226},\n",
       "   {'rouge-1': 0.18306558801066164,\n",
       "    'rouge-2': 0.08388788387518814,\n",
       "    'rouge-l': 1.1764934700626104},\n",
       "   {'rouge-1': 0.3098188871896764,\n",
       "    'rouge-2': 0.1061501360591906,\n",
       "    'rouge-l': 1.3727250615087547},\n",
       "   {'rouge-1': 0.3001768832581805,\n",
       "    'rouge-2': 0.10371390622307727,\n",
       "    'rouge-l': 1.3129943514913671}]),\n",
       " 5: ([0,\n",
       "   1.2223351551624035e-05,\n",
       "   0.00011397035266587366,\n",
       "   0,\n",
       "   9.262341057550601e-06,\n",
       "   8.523447405908206e-05,\n",
       "   0,\n",
       "   6.251364217290046e-05,\n",
       "   0.0001156991719806687],\n",
       "  [{'rouge-1': 0.15434381952912585,\n",
       "    'rouge-2': 0.07982965793848248,\n",
       "    'rouge-l': 1.0385191151017406},\n",
       "   {'rouge-1': 0.28892460981455564,\n",
       "    'rouge-2': 0.1373954142940814,\n",
       "    'rouge-l': 1.6321562650385815},\n",
       "   {'rouge-1': 0.32259368819671325,\n",
       "    'rouge-2': 0.12895339808507023,\n",
       "    'rouge-l': 1.5446816554373064},\n",
       "   {'rouge-1': 0.16171485817608064,\n",
       "    'rouge-2': 0.07282854739272536,\n",
       "    'rouge-l': 1.0302342500303532},\n",
       "   {'rouge-1': 0.310229191181569,\n",
       "    'rouge-2': 0.15249625456989366,\n",
       "    'rouge-l': 1.70567575892863},\n",
       "   {'rouge-1': 0.31563395928166244,\n",
       "    'rouge-2': 0.1313326975527053,\n",
       "    'rouge-l': 1.5026753358548843},\n",
       "   {'rouge-1': 0.1453716489159317,\n",
       "    'rouge-2': 0.04940322767908976,\n",
       "    'rouge-l': 0.7617407966239739},\n",
       "   {'rouge-1': 0.34608023749123246,\n",
       "    'rouge-2': 0.1359511832349167,\n",
       "    'rouge-l': 1.4544537365458818},\n",
       "   {'rouge-1': 0.3299457104293538,\n",
       "    'rouge-2': 0.14397698913380866,\n",
       "    'rouge-l': 1.4530777728129887}]),\n",
       " 6: ([0,\n",
       "   0.00012584360742569874,\n",
       "   0.0002591605527484468,\n",
       "   0,\n",
       "   0.00018464083797516736,\n",
       "   0.000393013325028549,\n",
       "   0,\n",
       "   0,\n",
       "   0.0006498925589403986],\n",
       "  [{'rouge-1': 0.19973775876251673,\n",
       "    'rouge-2': 0.09267007587461108,\n",
       "    'rouge-l': 1.205967018360259},\n",
       "   {'rouge-1': 0.2876360231860221,\n",
       "    'rouge-2': 0.09863086444927431,\n",
       "    'rouge-l': 1.333347454290113},\n",
       "   {'rouge-1': 0.3071773825098597,\n",
       "    'rouge-2': 0.10498650416248348,\n",
       "    'rouge-l': 1.3240619190519027},\n",
       "   {'rouge-1': 0.19038306651032258,\n",
       "    'rouge-2': 0.08559122097336175,\n",
       "    'rouge-l': 1.05846314992803},\n",
       "   {'rouge-1': 0.2948282745057791,\n",
       "    'rouge-2': 0.10652578206122404,\n",
       "    'rouge-l': 1.301420037457033},\n",
       "   {'rouge-1': 0.2904747297591531,\n",
       "    'rouge-2': 0.08804506190257574,\n",
       "    'rouge-l': 1.1917700330219398},\n",
       "   {'rouge-1': 0.17835689056061754,\n",
       "    'rouge-2': 0.07920063405797102,\n",
       "    'rouge-l': 0.9635758842317981},\n",
       "   {'rouge-1': 0.1931460589829711,\n",
       "    'rouge-2': 0.04290586666282879,\n",
       "    'rouge-l': 0.88310062480669},\n",
       "   {'rouge-1': 0.27908323060415824,\n",
       "    'rouge-2': 0.10556762171178788,\n",
       "    'rouge-l': 1.204690424630868}]),\n",
       " 7: ([2.330758411021561e-06,\n",
       "   1.7225912760699752e-06,\n",
       "   6.674951937116633e-05,\n",
       "   0,\n",
       "   1.6495568384607277e-05,\n",
       "   7.916382200035624e-05,\n",
       "   0,\n",
       "   4.056191516508726e-05,\n",
       "   0.0002079464924105836],\n",
       "  [{'rouge-1': 0.09950074063376481,\n",
       "    'rouge-2': 0.018960409673407168,\n",
       "    'rouge-l': 0.490496406076262},\n",
       "   {'rouge-1': 0.24496085560611985,\n",
       "    'rouge-2': 0.0639090629940949,\n",
       "    'rouge-l': 1.06764351395612},\n",
       "   {'rouge-1': 0.2725614355107936,\n",
       "    'rouge-2': 0.07502486907736063,\n",
       "    'rouge-l': 1.0627957465402793},\n",
       "   {'rouge-1': 0.1186831325885291,\n",
       "    'rouge-2': 0.028588657565534633,\n",
       "    'rouge-l': 0.5654661477970854},\n",
       "   {'rouge-1': 0.2601202040206085,\n",
       "    'rouge-2': 0.06606675614976859,\n",
       "    'rouge-l': 1.089045498750378},\n",
       "   {'rouge-1': 0.25185451684488963,\n",
       "    'rouge-2': 0.05450439111876852,\n",
       "    'rouge-l': 0.9988072499318956},\n",
       "   {'rouge-1': 0.12484666149289507,\n",
       "    'rouge-2': 0.029509277413485063,\n",
       "    'rouge-l': 0.5961112682335944},\n",
       "   {'rouge-1': 0.25218442204498753,\n",
       "    'rouge-2': 0.06016375872896641,\n",
       "    'rouge-l': 1.023552769219137},\n",
       "   {'rouge-1': 0.2468408404827655,\n",
       "    'rouge-2': 0.05515463623417062,\n",
       "    'rouge-l': 0.8786230614852714}])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:48:44.263411Z",
     "start_time": "2025-03-05T16:48:44.254884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for questions_number, (bleu, rouge) in results.items():\n",
    "    avg_bleu = np.mean(bleu)\n",
    "    max_bleu = np.max(bleu)\n",
    "    min_bleu = np.min(bleu)\n",
    "    std_bleu = np.std(bleu)\n",
    "\n",
    "    for entry in rouge:\n",
    "        r1 = entry['rouge-1']\n",
    "        r2 = entry['rouge-2']\n",
    "        r3 = entry['rouge-l']\n",
    "\n",
    "    avg_rouge1 = np.mean(r1)\n",
    "    max_rouge1 = np.max(r1)\n",
    "    min_rouge1 = np.min(r1)\n",
    "    std_rouge1 = np.std(r1)\n",
    "\n",
    "    avg_rouge2 = np.mean(r2)\n",
    "    max_rouge2 = np.max(r2)\n",
    "    min_rouge2 = np.min(r2)\n",
    "    std_rouge2 = np.std(r2)\n",
    "\n",
    "    avg_rougel = np.mean(r3)\n",
    "    max_rougel = np.max(r3)\n",
    "    min_rougel = np.min(r3)\n",
    "    std_rougel = np.std(r3)\n",
    "\n",
    "\n",
    "    print('BLEU:', questions_number, 'mean:',avg_bleu,'MAX:', max_bleu,'MIN:', min_bleu,'SD:', std_bleu)\n",
    "\n",
    "    print('ROUGE-1:', questions_number, '&', avg_rouge1,'&', max_rouge1,'&', min_rouge1,'&', std_rouge1)\n",
    "    print('ROUGE-2:', questions_number, '&', avg_rouge2,'&', max_rouge2,'&', min_rouge2,'&', std_rouge2)\n",
    "    print('ROUGE-L:', questions_number, '&', avg_rougel,'&', max_rougel,'&', min_rougel,'&', std_rougel)\n",
    "\n"
   ],
   "id": "66752a76f15284dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 1 mean: 0.00014289511590841905 MAX: 0.0007344395230440278 MIN: 0.0 SD: 0.0002706818806472494\n",
      "ROUGE-1: 1 & 0.30679202102213804 & 0.30679202102213804 & 0.30679202102213804 & 0.0\n",
      "ROUGE-2: 1 & 0.10520831701294711 & 0.10520831701294711 & 0.10520831701294711 & 0.0\n",
      "ROUGE-L: 1 & 1.283218785269201 & 1.283218785269201 & 1.283218785269201 & 0.0\n",
      "BLEU: 2 mean: 2.4478821854706948e-05 MAX: 0.00013355611113808304 MIN: 0.0 SD: 4.181585333934391e-05\n",
      "ROUGE-1: 2 & 0.28823917026788487 & 0.28823917026788487 & 0.28823917026788487 & 0.0\n",
      "ROUGE-2: 2 & 0.08961991959025033 & 0.08961991959025033 & 0.08961991959025033 & 0.0\n",
      "ROUGE-L: 2 & 1.2018168438563583 & 1.2018168438563583 & 1.2018168438563583 & 0.0\n",
      "BLEU: 3 mean: 0.00011485790191717418 MAX: 0.00028426541111959574 MIN: 0.0 SD: 0.00011787413108397185\n",
      "ROUGE-1: 3 & 0.3069594871170956 & 0.3069594871170956 & 0.3069594871170956 & 0.0\n",
      "ROUGE-2: 3 & 0.12213666380901514 & 0.12213666380901514 & 0.12213666380901514 & 0.0\n",
      "ROUGE-L: 3 & 1.3111355569187926 & 1.3111355569187926 & 1.3111355569187926 & 0.0\n",
      "BLEU: 4 mean: 3.9163159244392166e-05 MAX: 0.00018633556344816514 MIN: 0.0 SD: 5.481348267069119e-05\n",
      "ROUGE-1: 4 & 0.3001768832581805 & 0.3001768832581805 & 0.3001768832581805 & 0.0\n",
      "ROUGE-2: 4 & 0.10371390622307727 & 0.10371390622307727 & 0.10371390622307727 & 0.0\n",
      "ROUGE-L: 4 & 1.3129943514913671 & 1.3129943514913671 & 1.3129943514913671 & 0.0\n",
      "BLEU: 5 mean: 4.432259260974439e-05 MAX: 0.0001156991719806687 MIN: 0.0 SD: 4.7261896860675786e-05\n",
      "ROUGE-1: 5 & 0.3299457104293538 & 0.3299457104293538 & 0.3299457104293538 & 0.0\n",
      "ROUGE-2: 5 & 0.14397698913380866 & 0.14397698913380866 & 0.14397698913380866 & 0.0\n",
      "ROUGE-L: 5 & 1.4530777728129887 & 1.4530777728129887 & 1.4530777728129887 & 0.0\n",
      "BLEU: 6 mean: 0.00017917232023536227 MAX: 0.0006498925589403986 MIN: 0.0 SD: 0.0002121289894402178\n",
      "ROUGE-1: 6 & 0.27908323060415824 & 0.27908323060415824 & 0.27908323060415824 & 0.0\n",
      "ROUGE-2: 6 & 0.10556762171178788 & 0.10556762171178788 & 0.10556762171178788 & 0.0\n",
      "ROUGE-L: 6 & 1.204690424630868 & 1.204690424630868 & 1.204690424630868 & 0.0\n",
      "BLEU: 7 mean: 4.610785189098803e-05 MAX: 0.0002079464924105836 MIN: 0.0 SD: 6.390663258527592e-05\n",
      "ROUGE-1: 7 & 0.2468408404827655 & 0.2468408404827655 & 0.2468408404827655 & 0.0\n",
      "ROUGE-2: 7 & 0.05515463623417062 & 0.05515463623417062 & 0.05515463623417062 & 0.0\n",
      "ROUGE-L: 7 & 0.8786230614852714 & 0.8786230614852714 & 0.8786230614852714 & 0.0\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment Analysis",
   "id": "c0de11f7b6b75e8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T17:15:58.566707Z",
     "start_time": "2025-03-05T17:15:48.118785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "specific_model = pipeline(model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "output = specific_model(df['Answer'].tolist(),truncation=True, max_length=512)\n",
    "\n",
    "stars = list()\n",
    "for score in output:\n",
    "    l = score['label']\n",
    "    stars.append(l)\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "star_counts = Counter(stars)\n",
    "\n",
    "# Print the results\n",
    "for star, count in star_counts.items():\n",
    "    print(f\"{star}: {count} ({count / len(stars):.2%})\")"
   ],
   "id": "5b8f98e1608ef67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 star: 26 (41.27%)\n",
      "2 stars: 10 (15.87%)\n",
      "4 stars: 18 (28.57%)\n",
      "3 stars: 5 (7.94%)\n",
      "5 stars: 4 (6.35%)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BertScore",
   "id": "8d6b4ba961e432ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:26:15.682642Z",
     "start_time": "2025-03-10T09:11:41.652021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bert_score import score\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def chunk_text(text, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text and splits it into chunks of max_length tokens.\n",
    "    Each chunk is then decoded back into a string.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "    token_chunks = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
    "    return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in token_chunks]\n",
    "\n",
    "def process_pair(candidate, reference, tokenizer, model_type):\n",
    "    \"\"\"\n",
    "    Process a single candidate-reference pair:\n",
    "    1. Chunk each text.\n",
    "    2. Pair up corresponding chunks.\n",
    "    3. Compute BERTScore over all pairs and average the results.\n",
    "    \"\"\"\n",
    "    candidate_chunks = chunk_text(candidate, tokenizer, max_length=512)\n",
    "    reference_chunks = chunk_text(reference, tokenizer, max_length=512)\n",
    "\n",
    "    num_chunks = min(len(candidate_chunks), len(reference_chunks))\n",
    "    if num_chunks == 0:\n",
    "        raise ValueError(\"One of the texts is empty after chunking.\")\n",
    "\n",
    "    # Use only the aligned number of chunks\n",
    "    candidate_chunks = candidate_chunks[:num_chunks]\n",
    "    reference_chunks = reference_chunks[:num_chunks]\n",
    "\n",
    "    P, R, F1 = score(candidate_chunks, reference_chunks, model_type=model_type, verbose=False)\n",
    "    return {\"precision\": P.mean().item(), \"recall\": R.mean().item(), \"f1\": F1.mean().item()}\n",
    "\n",
    "def calculate_bertscore(reference_text, candidate_text, model_type=\"bert-base-multilingual-cased\"):\n",
    "    \"\"\"\n",
    "    Calculates the average BERTScore between candidate_text and reference_text.\n",
    "    Handles both single string inputs and lists of strings.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "    # Both candidate_text and reference_text are strings.\n",
    "    if isinstance(candidate_text, str) and isinstance(reference_text, str):\n",
    "        return process_pair(candidate_text, reference_text, tokenizer, model_type)\n",
    "\n",
    "    # If one of the inputs is a list, compute pairwise scores and average.\n",
    "    elif isinstance(candidate_text, list) and isinstance(reference_text, list):\n",
    "        results = [process_pair(c, r, tokenizer, model_type) for c, r in zip(candidate_text, reference_text)]\n",
    "    elif isinstance(candidate_text, list):\n",
    "        results = [process_pair(c, reference_text, tokenizer, model_type) for c in candidate_text]\n",
    "    elif isinstance(reference_text, list):\n",
    "        results = [process_pair(candidate_text, r, tokenizer, model_type) for r in reference_text]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input types. Expected string or list of strings.\")\n",
    "\n",
    "    avg_precision = sum(res[\"precision\"] for res in results) / len(results)\n",
    "    avg_recall = sum(res[\"recall\"] for res in results) / len(results)\n",
    "    avg_f1 = sum(res[\"f1\"] for res in results) / len(results)\n",
    "\n",
    "    return {\"precision\": avg_precision, \"recall\": avg_recall, \"f1\": avg_f1}\n",
    "\n",
    "# Example usage within your loop:\n",
    "from tqdm import tqdm  # Ensure you have tqdm imported\n",
    "\n",
    "res = dict()\n",
    "for i in tqdm(range(1, 8), desc='Calculating BERTScores...'):\n",
    "    _df = df_grouped.get_group(str(i))\n",
    "\n",
    "    def t(prompt):\n",
    "        return prompt.split('_')[3]\n",
    "\n",
    "    prompt = _df['Prompt'].apply(t)\n",
    "    _df['Answer'].apply(preprocess_text)\n",
    "\n",
    "    bert_scores = list()\n",
    "    answers = _df['Answer'].tolist()\n",
    "\n",
    "    # Compare each answer to all other answers\n",
    "    for answer in answers:\n",
    "        # Create a copy of answers without the current one\n",
    "        remaining_answers = answers.copy()\n",
    "        remaining_answers.remove(answer)\n",
    "\n",
    "        # Here, candidate is a string and reference is a list.\n",
    "        score_result = calculate_bertscore(remaining_answers, answer)\n",
    "        bert_scores.append(score_result)\n",
    "\n",
    "    res[i] = bert_scores\n"
   ],
   "id": "42d5a1ef0d8a6c89",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating BERTScores...:  43%|████▎     | 3/7 [05:44<07:37, 114.31s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating BERTScores...:  71%|███████▏  | 5/7 [09:36<03:49, 114.74s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating BERTScores...:  86%|████████▌ | 6/7 [11:26<01:53, 113.20s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating BERTScores...: 100%|██████████| 7/7 [14:34<00:00, 124.86s/it]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:30:22.436768Z",
     "start_time": "2025-03-10T09:30:22.431730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for question_num, bs in res.items():\n",
    "    l = list()\n",
    "    for b in bs:\n",
    "        l.append(b['f1'])\n",
    "        #print(question_num, b['f1'])\n",
    "\n",
    "    print(\"MEAN:\", np.mean(l), \"MIN:\", np.min(l), \"MAX:\", np.max(l), \"SD:\", np.std(l))"
   ],
   "id": "9da2a11365a31a07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: 0.728717086215814 MIN: 0.6992478892207146 MAX: 0.7532092332839966 SD: 0.015782590833472977\n",
      "MEAN: 0.7303109980291791 MIN: 0.6903219297528267 MAX: 0.7499452382326126 SD: 0.016474867269818345\n",
      "MEAN: 0.711606562965446 MIN: 0.6879376620054245 MAX: 0.7302430421113968 SD: 0.011967532619847721\n",
      "MEAN: 0.709494001335568 MIN: 0.6919497102499008 MAX: 0.724240817129612 SD: 0.010953838281416533\n",
      "MEAN: 0.7300494189063708 MIN: 0.7041249796748161 MAX: 0.7524049282073975 SD: 0.01700715225362556\n",
      "MEAN: 0.7135264360242419 MIN: 0.6994640901684761 MAX: 0.7276577427983284 SD: 0.008442125626552721\n",
      "MEAN: 0.6753534716036584 MIN: 0.6536493971943855 MAX: 0.6927966251969337 SD: 0.011703807639520059\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:12:36.868068Z",
     "start_time": "2025-03-10T09:58:16.873970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bert_score import score\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def chunk_text(text, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text into token ids, splits them into chunks of max_length,\n",
    "    decodes each chunk back to text, and then verifies that the re-tokenized chunk\n",
    "    does not exceed max_length tokens. If it does, it truncates the re-tokenized chunk.\n",
    "    \"\"\"\n",
    "    # Encode text to token ids (including special tokens)\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "    # Split tokens into chunks of size max_length\n",
    "    token_chunks = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
    "    decoded_chunks = []\n",
    "    for chunk in token_chunks:\n",
    "        # Decode the chunk without cleaning up spaces to minimize re-tokenization differences\n",
    "        decoded = tokenizer.decode(chunk, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        # Re-tokenize the decoded chunk\n",
    "        new_tokens = tokenizer.encode(decoded, add_special_tokens=True)\n",
    "        # If re-tokenized chunk exceeds max_length, truncate it and decode again\n",
    "        if len(new_tokens) > max_length:\n",
    "            new_tokens = new_tokens[:max_length]\n",
    "            decoded = tokenizer.decode(new_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        decoded_chunks.append(decoded)\n",
    "    return decoded_chunks\n",
    "\n",
    "def process_pair(candidate, reference, tokenizer, model_type):\n",
    "    \"\"\"\n",
    "    Processes a single candidate-reference pair by:\n",
    "      1. Chunking both texts,\n",
    "      2. Pairing up corresponding chunks (using the minimum number of chunks),\n",
    "      3. Computing BERTScore on each pair, and\n",
    "      4. Averaging the resulting scores.\n",
    "    \"\"\"\n",
    "    candidate_chunks = chunk_text(candidate, tokenizer, max_length=512)\n",
    "    reference_chunks = chunk_text(reference, tokenizer, max_length=512)\n",
    "\n",
    "    # Ensure we only compare up to the minimum number of chunks\n",
    "    num_chunks = min(len(candidate_chunks), len(reference_chunks))\n",
    "    if num_chunks == 0:\n",
    "        raise ValueError(\"One of the texts is empty after chunking.\")\n",
    "\n",
    "    candidate_chunks = candidate_chunks[:num_chunks]\n",
    "    reference_chunks = reference_chunks[:num_chunks]\n",
    "\n",
    "    P, R, F1 = score(candidate_chunks, reference_chunks, model_type=model_type, verbose=False)\n",
    "    return {\"precision\": P.mean().item(), \"recall\": R.mean().item(), \"f1\": F1.mean().item()}\n",
    "\n",
    "def calculate_bertscore(reference_text, candidate_text, model_type=\"bert-base-multilingual-cased\"):\n",
    "    \"\"\"\n",
    "    Calculates the average BERTScore between candidate_text and reference_text.\n",
    "    Accepts either strings or lists of strings.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "    # When both inputs are single strings\n",
    "    if isinstance(candidate_text, str) and isinstance(reference_text, str):\n",
    "        return process_pair(candidate_text, reference_text, tokenizer, model_type)\n",
    "\n",
    "    # When both inputs are lists of strings (aligned pair-wise)\n",
    "    elif isinstance(candidate_text, list) and isinstance(reference_text, list):\n",
    "        results = [process_pair(c, r, tokenizer, model_type) for c, r in zip(candidate_text, reference_text)]\n",
    "    # When candidate_text is a list and reference_text is a single string\n",
    "    elif isinstance(candidate_text, list):\n",
    "        results = [process_pair(c, reference_text, tokenizer, model_type) for c in candidate_text]\n",
    "    # When reference_text is a list and candidate_text is a single string\n",
    "    elif isinstance(reference_text, list):\n",
    "        results = [process_pair(candidate_text, r, tokenizer, model_type) for r in reference_text]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input types. Expected string or list of strings.\")\n",
    "\n",
    "    avg_precision = sum(res[\"precision\"] for res in results) / len(results)\n",
    "    avg_recall = sum(res[\"recall\"] for res in results) / len(results)\n",
    "    avg_f1 = sum(res[\"f1\"] for res in results) / len(results)\n",
    "\n",
    "    return {\"precision\": avg_precision, \"recall\": avg_recall, \"f1\": avg_f1}\n",
    "\n",
    "# Example usage within your loop:\n",
    "from tqdm import tqdm  # Ensure tqdm is imported\n",
    "\n",
    "for i in tqdm(range(1, 8), desc='Calculating BERTScores...'):\n",
    "    _df = df_grouped.get_group(str(i))\n",
    "\n",
    "    def t(prompt):\n",
    "        return prompt.split('_')[3]\n",
    "\n",
    "    prompt = _df['Prompt'].apply(t)\n",
    "    _df['Answer'].apply(preprocess_text)\n",
    "\n",
    "    bert_scores = list()\n",
    "    answers = _df['Answer'].tolist()\n",
    "\n",
    "    # Compare each answer to all other answers\n",
    "    for answer in answers:\n",
    "        # Create a copy of answers without the current one\n",
    "        remaining_answers = answers.copy()\n",
    "        remaining_answers.remove(answer)\n",
    "\n",
    "        # Here, candidate is a string and reference is a list.\n",
    "        score_result = calculate_bertscore(remaining_answers, answer)\n",
    "        bert_scores.append(score_result)\n"
   ],
   "id": "b672fd7622953fd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating BERTScores...:  43%|████▎     | 3/7 [05:41<07:37, 114.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating BERTScores...:  71%|███████▏  | 5/7 [09:58<04:04, 122.25s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating BERTScores...:  86%|████████▌ | 6/7 [12:01<02:02, 122.71s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating BERTScores...: 100%|██████████| 7/7 [14:19<00:00, 122.85s/it]\n"
     ]
    }
   ],
   "execution_count": 82
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
